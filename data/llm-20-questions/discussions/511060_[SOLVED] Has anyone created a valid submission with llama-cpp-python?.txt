[Melinda](/melindaweathers) · 38th in this Competition · Posted 3 months ago


### [SOLVED] Has anyone created a valid submission with llama-cpp-python?
Hello, new friends. I have a version of the competition code using llama-cpp-
python running beautifully on my M1 Macbook, but now I have spent quite a
while trying to get a version of it working in a valid submission on Kaggle
and have not figured out how. I'm wondering if anyone else has gotten this to
work, and if anyone has tips to get my llama submission to be successful.
Here is a notebook showing what happens when trying to pip install on the
latest environment - <https://www.kaggle.com/code/melindaweathers/error-
installing-llama-cpp-python> . I am considering submitting this as an issue on
the kaggle docker github, but I'm not actually sure if it is an issue with
kaggle or llama-cpp-python, so I haven't done that.
I am trying to use the gguf file from this
[notebook](https://www.kaggle.com/code/raki21/llama-3-gguf-with-llama-
cpp/notebook), and I am actually able to install llama-cpp-python on kaggle
with the old environment and wheels used in the notebook, but given that it
doesn't work for me on the latest docker image, and the agents are probably
run on the latest docker image, this approach seems unlikely to work as a
submission. (In fact I tried it and it did not work)
I was able to get an old version of llama-cpp-python (0.2.25) to run in kaggle
on the latest docker image, but another issue I am having (as mentioned
[here](https://www.kaggle.com/competitions/llm-20-questions/discussion/505650#2859210))
is that trying to pip install llama-cpp-python to a target folder with the
`-t` option throws a large number of errors about compatibility. I've tried
ignoring these errors and submitting anyways, but so far no dice. (I think
it's not properly using the GPU when I ignore the errors)
Any suggestions?


## 3 Comments


### [Melinda](/melindaweathers)
If anyone here is looking for more specifics about how this was solved, I
added an example towards the bottom of this notebook -
<https://www.kaggle.com/code/melindaweathers/installing-running-llama-cpp-
python?scriptVersionId=184413038>


### [omqriko](/omarkkhalifa)
Use this  
`!CMAKE_ARGS="-DLLAMA_CUBLAS=on" pip install llama-cpp-python -U --force-
reinstall --extra-index-url https://abetlen.github.io/llama-cpp-
python/whl/cu121`


### [Melinda](/melindaweathers)
Thanks for the suggestion! Unfortunately I'm seeing the same error with that
as well -
    
    
    Target "ggml" links to:
            CUDA::cuda_driver
            but the target was not found. 
    
    
    content_copy
[Here](https://www.kaggle.com/code/melindaweathers/error-installing-llama-cpp-
python?scriptVersionId=183134477) is a new version of a notebook showing that
full error message.


### [omqriko](/omarkkhalifa)
Okay finally got there with some debugging, here it is:
    
    
    !CMAKE_ARGS="-DLLAMA_CUBLAS=on" pip install llama-cpp-python==0.2.77 -U --force-reinstall --no-cache-dir --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu121
    
    
    content_copy


### [Melinda](/melindaweathers)
Thank you for another suggestion! That didn't work for me for some reason
either, but I did find something that seems to have worked.
I added this [input](https://www.kaggle.com/datasets/mikeee8/llama-cpp-python-
py310-cuda-4-kaggle/data) and copied the folders to my
/kaggle/working/submission/lib and then also did `pip install -t
/kaggle/working/submission/lib "diskcache>=5.6.1" "jinja2>=2.11.3"
"numpy>=1.20.0" "typing-extensions>=4.5.0"` and ignored the conflicts it
listed after `ERROR: pip's dependency resolver does not currently take into
account all the packages that are installed. This behaviour is the source of
the following dependency conflicts.`
Previously I didn't realize that when you install into a target directory, pip
always ignores the packages installed in the system, so I guess those errors
are safe to ignore in this case.
Anyways the agent passed the validation round at least now using llama-cpp-
python!
